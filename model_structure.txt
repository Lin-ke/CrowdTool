FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)FusionModel(
  (block1): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(256, 768, kernel_size=(2, 2), stride=(2, 2))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block4): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (t_conv): Sequential(
      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (block5): Block(
    (rgb_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (t_conv): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU(inplace=True)
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU(inplace=True)
    )
    (Encoder): Encoder(
      (x_layers): ModuleList(
        (0): Encoderlayer(
          (patchembedRgb): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (patchembedT): patchembed(
            (proj): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (cross_att): MultiHeadAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (qkv1): Linear(in_features=768, out_features=2304, bias=False)
            (conv2d_RGB): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv2d_T): Sequential(
              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): ReLU(inplace=True)
              (2): Dropout(p=0.5, inplace=False)
              (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): ReLU(inplace=True)
              (5): Dropout(p=0.5, inplace=False)
            )
            (conv1d): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (conv1d2): Sequential(
              (0): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (atten_drop1): Dropout(p=0.1, inplace=False)
            (atten_drop2): Dropout(p=0.1, inplace=False)
            (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (proj1): Linear(in_features=768, out_features=768, bias=True)
            (proj2): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop1): Dropout(p=0.1, inplace=False)
            (proj_drop2): Dropout(p=0.1, inplace=False)
          )
          (FFN_RGB): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (FFN_T): MLP(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate=none)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.1, inplace=False)
            (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (conv1d1): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
          (conv1d2): Sequential(
            (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
    )
  )
  (conv1d): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (24): ReLU(inplace=True)
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (26): ReLU(inplace=True)
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): ReLU(inplace=True)
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (33): ReLU(inplace=True)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): ReLU(inplace=True)
  )
  (reg_layer): Sequential(
    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
)